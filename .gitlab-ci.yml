stages:
  - validate
  - test
  - integration
  - docs
  - build
  - release

variables:
  ANSIBLE_FORCE_COLOR: "true"
  FF_WAIT_FOR_POD_TO_BE_REACHABLE: 1
  # Docker connection resilience
  DOCKER_DRIVER: overlay2
  DOCKER_BUILDKIT: 1
  # Use CI-specific config for Docker temp directory issues
  ANSIBLE_CONFIG: "$CI_PROJECT_DIR/ansible-ci.cfg"
  # Force Ansible to use /tmp for all temp operations
  ANSIBLE_REMOTE_TEMP: "/tmp/ansible-tmp"
  ANSIBLE_LOCAL_TEMP: "/tmp/ansible-tmp"

# Global cache configuration
cache:
  # Use same cache for all jobs with same key
  policy: pull-push
  # Fallback cache for different branches
  fallback_keys:
    - cache-main

# Comprehensive validation - combines all linting and syntax checks
validate-all:
  stage: validate
  image: registry.wolskinet.com:5050/ansible/collections/infrastructure/validation:latest
  cache:
    key: "validation-$CI_COMMIT_REF_SLUG"
    paths:
      - /root/.cache/pip/
      - /root/.ansible/collections/
      - /var/cache/apt/
      - /root/.cache/pre-commit/
  except:
    - tags
  script:
    # Tools already pre-installed in custom image, just install collections
    - |
      if [ ! -f /root/.ansible/collections/.installed ]; then
        echo "Installing Ansible collections (not cached)..."
        for i in {1..3}; do
          echo "Attempt $i: Installing ansible collections..."
          if ansible-galaxy collection install -r requirements.yml --force; then
            echo "✅ Collections installed successfully"
            touch /root/.ansible/collections/.installed
            break
          else
            echo "❌ Attempt $i failed, retrying in 10 seconds..."
            sleep 10
          fi
          if [ $i -eq 3 ]; then
            echo "❌ All attempts failed"
            exit 1
          fi
        done
      else
        echo "✅ Using cached Ansible collections"
      fi
    # Install current collection being tested
    - echo "Installing current collection wolskies.infrastructure..."
    - ansible-galaxy collection install . --force

    # Configure git to use HTTPS instead of HTTP
    - git config --global --add safe.directory $CI_PROJECT_DIR
    - git config --global url."https://oldgitlab.wolskinet.com/".insteadOf "http://oldgitlab.wolskinet.com/"
    # Run pre-commit checks (includes yamllint, prettier, custom checks)
    - pre-commit run --all-files || true # Non-blocking but shows issues

    # Run ansible-lint (critical for Ansible best practices)
    - ansible-lint

    # Run syntax check (ensures playbooks are parseable)
    - ansible-playbook --syntax-check playbooks/*.yml 2>/dev/null || echo "No playbooks to syntax check"

    # Secret scanning with gitleaks (final backstop)
    - echo "Installing gitleaks..."
    - |
      if ! command -v gitleaks &> /dev/null; then
        curl -sSL https://github.com/gitleaks/gitleaks/releases/download/v8.18.4/gitleaks_8.18.4_linux_x64.tar.gz | tar xz -C /usr/local/bin gitleaks
        chmod +x /usr/local/bin/gitleaks
      fi
    - echo "Running secret scan with gitleaks..."
    - gitleaks detect --config .gitleaks.toml --verbose --no-git || echo "⚠️  Secrets detected - review findings above"
    - echo "Secret scanning complete"

    # Validate documentation generation and RST syntax
    - echo "Installing documentation tools..."
    - pip install --break-system-packages pyyaml rstcheck
    - echo "Generating and validating documentation..."
    - python3 scripts/generate_enhanced_docs.py
    - rstcheck docs/generated/*.rst || echo "No generated docs to check"
    - echo "Documentation generation and validation passed"

    - echo "All validation checks completed"

# Template for molecule test jobs
.molecule_test_template:
  image: python:3.13-slim
  services:
    - docker:24-dind
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ""
    DOCKER_DRIVER: overlay2
    FF_NETWORK_PER_BUILD: "true"
  cache:
    key: "molecule-$CI_COMMIT_REF_SLUG"
    paths:
      - /root/.cache/pip/
      - /root/.ansible/collections/
      - /var/cache/apt/
      - /var/lib/apt/lists/
  before_script:
    # Install system packages like we do locally
    - apt-get update -qq
    - apt-get install -y -qq ansible docker.io make dnsutils python3-pip
    # Wait for Docker daemon and login to avoid rate limiting
    - echo "Waiting for Docker daemon..."
    - for i in {1..30}; do docker info >/dev/null 2>&1 && break || (echo "Attempt $i failed, retrying..."; sleep 2); done
    - echo "Logging into Docker Hub..."
    - echo "$DOCKER_HUB_TOKEN" | docker login -u "$DOCKER_HUB_USER" --password-stdin || echo "⚠️  Docker Hub login failed - proceeding with anonymous pulls (may hit rate limits)"
    # Ensure collections directory exists for caching
    - mkdir -p /root/.ansible/collections
    # Install molecule and testing tools via pip (user install, no venv)
    - pip install --break-system-packages molecule[docker] molecule-plugins[docker] pytest-testinfra
    # Install collections with caching and retry for transient Galaxy failures
    - |
      if [ ! -f /root/.ansible/collections/.installed ]; then
        echo "Installing Ansible collections (not cached)..."
        for i in {1..3}; do
          echo "Attempt $i: Installing ansible collections..."
          if ansible-galaxy collection install -r requirements.yml --force; then
            echo "✅ Collections installed successfully"
            touch /root/.ansible/collections/.installed
            break
          else
            echo "❌ Attempt $i failed, retrying in 10 seconds..."
            sleep 10
          fi
          if [ $i -eq 3 ]; then
            echo "❌ All attempts failed"
            exit 1
          fi
        done
      else
        echo "✅ Using cached Ansible collections"
      fi
    # Install current collection being tested
    - echo "Installing current collection wolskies.infrastructure..."
    - ansible-galaxy collection install . --force
    - echo "=== Installed collections ==="
    - ansible-galaxy collection list | grep -E "(community\.general|ansible\.posix|community\.docker|wolskies\.infrastructure)"
    - echo "=== Collection paths ==="
    - ansible --version | grep "collection location"
    # Debug DNS and network connectivity
    - echo "Checking network connectivity..."
    - nslookup docker || echo "DNS lookup failed"
    - ping -c 3 docker || echo "Ping failed"
    # Wait for Docker with enhanced retry logic
    - echo "Waiting for Docker daemon..."
    - for i in {1..60}; do docker info >/dev/null 2>&1 && break || (echo "Attempt $i failed, retrying..."; sleep 2); done
    - docker info

# Individual role-level tests (run in parallel for faster feedback)
test-role-discovery:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/discovery && molecule test
    - echo "✅ Discovery role tests passed"
  except:
    - tags

# REMOVED: test-docker - role not ready for production
# Docker compose functionality needs further development

# MOVED: test-minimal - moved to validate stage as validate-minimal-config
# Minimal configuration safety is a validation concern, not a functional test

# REMOVED: test-dotfiles - functionality consolidated into configure_users role
# Dotfiles deployment is now handled as part of per-user configuration

# Individual role-level tests (run in parallel for faster feedback)
test-role-nodejs:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/nodejs && molecule test
    - echo "✅ Node.js role tests passed"
  except:
    - tags

test-role-rust:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/rust && molecule test
    - echo "✅ Rust role tests passed"
  except:
    - tags

test-role-go:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/go && molecule test
    - echo "✅ Go role tests passed"
  except:
    - tags

test-role-neovim:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/neovim && molecule test
    - echo "✅ Neovim role tests passed"
  except:
    - tags

# Disabled: terminal_config tests fail in containers due to terminfo compilation limitations
# test-role-terminal-config:
#   extends: .molecule_test_template
#   stage: test
#   script:
#     - cd roles/terminal_config && molecule test
#     - echo "✅ Terminal config role tests passed"

test-role-os-configuration:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/os_configuration && molecule test -- --skip-tags no-container
    - echo "✅ OS configuration role tests passed"
  except:
    - tags

test-role-manage-packages:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/manage_packages && molecule test -- --skip-tags no-container
    - echo "✅ Package management role tests passed"
  except:
    - tags

test-role-manage-security-services:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/manage_security_services && molecule test
    - echo "✅ Security services role tests passed"
  except:
    - tags

test-role-configure-user:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/configure_users && molecule test
    - echo "✅ User configuration role tests passed"
  except:
    - tags

test-role-manage-flatpak:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/manage_flatpak && molecule test
    - echo "✅ Flatpak management role tests passed (Ubuntu + Arch Linux)"
  except:
    - tags

test-role-manage-snap-packages:
  extends: .molecule_test_template
  stage: test
  script:
    - cd roles/manage_snap_packages && molecule test
    - echo "✅ Snap packages role tests passed"
  except:
    - tags

# Variable validation - ensures role variable passing and defaults work correctly
test-variable-validation:
  extends: .molecule_test_template
  stage: integration
  script:
    - molecule test -s minimal # Test robustness with empty/missing config
    - echo "✅ Variable validation and robustness tests passed"
  only:
    - main
    - merge_requests
  except:
    - tags

# =============================================================================
# DOCUMENTATION STAGE
# =============================================================================

# Build documentation with Sphinx
build-docs:
  stage: docs
  image: python:3.13-slim
  cache:
    key: "docs-$CI_COMMIT_REF_SLUG"
    paths:
      - /var/cache/apt/
      - /root/.cache/pip/
  before_script:
    - apt-get update -qq
    - apt-get install -y -qq git
    - pip install --break-system-packages rstcheck sphinx sphinx-rtd-theme
  script:
    - echo "Building Sphinx documentation..."

    # Generate Sphinx configuration
    - python3 scripts/create_sphinx_files.py docs
    - echo "Sphinx conf.py generated"

    # Create _static directory if it doesn't exist
    - mkdir -p docs/_static

    # Validate RST files
    - rstcheck docs/*.rst docs/*/*.rst || true
    - echo "RST validation complete"

    # Build Sphinx documentation
    - sphinx-build -b html docs public

    # Create .nojekyll for GitHub Pages compatibility
    - touch public/.nojekyll

    - echo "Sphinx documentation built successfully"
    - ls -la public/

  artifacts:
    paths:
      - public/
    expire_in: 1 week
  only:
    - main
    - merge_requests

# GitLab Pages deployment (only on main branch)
pages:
  stage: release
  image: alpine:latest
  dependencies:
    - build-docs
  script:
    - echo "Deploying documentation to GitLab Pages..."
    - ls -la public/
    - echo "Documentation ready for GitLab Pages"
    - echo "Documentation will be available at $CI_PAGES_URL"
  artifacts:
    paths:
      - public
  only:
    - main

# Documentation preview for merge requests
docs-preview:
  stage: docs
  dependencies:
    - build-docs
  script:
    - echo "Documentation preview generated for merge request"
    - echo "Preview artifacts contain built documentation"
    - echo "Download the artifacts to preview the documentation locally"
  artifacts:
    paths:
      - public/
    expire_in: 3 days
    name: "docs-preview-mr-${CI_MERGE_REQUEST_IID}"
  only:
    - merge_requests
  when: manual

# =============================================================================
# BUILD STAGE
# =============================================================================

# Collection build
collection-build:
  stage: build
  image: python:3.13-slim
  cache:
    key: "build-$CI_COMMIT_REF_SLUG"
    paths:
      - /var/cache/apt/
  script:
    - apt-get update -qq && apt-get install -y -qq ansible
    - ansible-galaxy collection build --force
    - ls -la *.tar.gz
    - echo "✅ Collection built successfully"
  artifacts:
    paths:
      - "*.tar.gz"
    expire_in: 1 week

# Version validation and tagging
version-check:
  stage: build
  image: python:3.13-slim
  script:
    - pip install --break-system-packages pyyaml
    - python3 -c "import yaml; print('Version:', yaml.safe_load(open('galaxy.yml'))['version'])"
    - echo "✅ Version validated"
  only:
    - tags

# =============================================================================
# RELEASE STAGE
# =============================================================================

# Create release tag and generate release notes
create-release:
  stage: release
  image: python:3.13-slim
  dependencies:
    - collection-build
  script:
    - apt-get update -qq && apt-get install -y -qq git curl
    - pip install --break-system-packages pyyaml
    - git config --global user.email "ci@wolskinet.com"
    - git config --global user.name "GitLab CI"
    - git config --global --add safe.directory $CI_PROJECT_DIR

    # Get version from galaxy.yml
    - export COLLECTION_VERSION=$(python3 -c "import yaml; print(yaml.safe_load(open('galaxy.yml'))['version'])")
    - export TAG_NAME="v${COLLECTION_VERSION}"
    - export TARBALL_NAME="wolskies-infrastructure-${COLLECTION_VERSION}.tar.gz"
    - echo "Creating release for version ${COLLECTION_VERSION} with tag ${TAG_NAME}"

    # Verify tarball exists
    - |
      if [ ! -f "$TARBALL_NAME" ]; then
        echo "❌ ERROR: Tarball $TARBALL_NAME not found"
        ls -la *.tar.gz || echo "No tar.gz files found"
        exit 1
      fi
      echo "✅ Found tarball: $TARBALL_NAME"

    # Generate release notes from commits since last tag
    - |
      LAST_TAG=$(git tag --sort=-creatordate | head -n1 || echo "")
      if [ -z "$LAST_TAG" ]; then
        echo "No previous tags found, generating release notes from beginning"
        COMMIT_RANGE="HEAD"
      else
        echo "Last tag: $LAST_TAG"
        COMMIT_RANGE="${LAST_TAG}..HEAD"
      fi

      echo "# Release Notes for ${TAG_NAME}" > RELEASE_NOTES.md
      echo "" >> RELEASE_NOTES.md
      echo "## Changes" >> RELEASE_NOTES.md
      git log $COMMIT_RANGE --pretty=format:"- %s (%h)" --no-merges >> RELEASE_NOTES.md
      echo "" >> RELEASE_NOTES.md
      echo "" >> RELEASE_NOTES.md
      echo "## Collection Info" >> RELEASE_NOTES.md
      echo "- **Version**: ${COLLECTION_VERSION}" >> RELEASE_NOTES.md
      echo "- **Build**: ${CI_PIPELINE_ID}" >> RELEASE_NOTES.md
      echo "- **Commit**: ${CI_COMMIT_SHA:0:8}" >> RELEASE_NOTES.md

    # Verify GITLAB_RELEASE_TOKEN is set
    - |
      if [ -z "$GITLAB_RELEASE_TOKEN" ]; then
        echo "❌ ERROR: GITLAB_RELEASE_TOKEN not set"
        echo "To enable release automation:"
        echo "1. Create a Project Access Token at Settings > Access Tokens"
        echo "2. Give it 'api' and 'write_repository' scopes"
        echo "3. Add it as CI/CD variable GITLAB_RELEASE_TOKEN"
        echo "4. If token is marked 'Protected', ensure 'main' branch is protected"
        exit 1
      fi
      echo "✅ GITLAB_RELEASE_TOKEN is set (first 8 chars: ${GITLAB_RELEASE_TOKEN:0:8}...)"

    # Create GitLab release using the API
    - |
      echo "Creating GitLab release..."
      RELEASE_RESPONSE=$(curl --request POST --header "PRIVATE-TOKEN: $GITLAB_RELEASE_TOKEN" \
           --header "Content-Type: application/json" \
           --data "{
             \"tag_name\": \"$TAG_NAME\",
             \"name\": \"wolskies.infrastructure $COLLECTION_VERSION\",
             \"description\": \"$(cat RELEASE_NOTES.md | sed 's/"/\\"/g' | tr '\n' ' ')\"
           }" \
           "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/releases")
      echo "$RELEASE_RESPONSE"

    # Upload tarball to Generic Package Registry
    - |
      echo "Uploading tarball to Package Registry..."
      PACKAGE_REGISTRY_URL="${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/wolskies-infrastructure/${COLLECTION_VERSION}/${TARBALL_NAME}"

      curl --request PUT --header "PRIVATE-TOKEN: $GITLAB_RELEASE_TOKEN" \
           --upload-file "${TARBALL_NAME}" \
           "${PACKAGE_REGISTRY_URL}"

      echo "✅ Tarball uploaded to Package Registry"
      echo "Package URL: ${PACKAGE_REGISTRY_URL}"

      # Link the package to the release
      curl --request POST --header "PRIVATE-TOKEN: $GITLAB_RELEASE_TOKEN" \
           --header "Content-Type: application/json" \
           --data "{
             \"name\": \"${TARBALL_NAME}\",
             \"url\": \"${PACKAGE_REGISTRY_URL}\",
             \"link_type\": \"package\"
           }" \
           "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/releases/${TAG_NAME}/assets/links"
      echo "✅ Package linked to release"

    - echo "✅ Release ${TAG_NAME} created successfully with tarball"
    - cat RELEASE_NOTES.md

    # Update CHANGELOG.md
    - |
      echo "Updating CHANGELOG.md..."
      export RELEASE_DATE=$(date +"%Y-%m-%d")

      if [ ! -f CHANGELOG.md ]; then
        echo "# Changelog" > CHANGELOG.md
        echo "" >> CHANGELOG.md
        echo "All notable changes to this project will be documented in this file." >> CHANGELOG.md
        echo "" >> CHANGELOG.md
      fi

      # Prepare new changelog entry
      echo "## [${COLLECTION_VERSION}] - ${RELEASE_DATE}" > CHANGELOG_NEW.md
      echo "" >> CHANGELOG_NEW.md
      cat RELEASE_NOTES.md | grep "^- " >> CHANGELOG_NEW.md || echo "No changes listed" >> CHANGELOG_NEW.md
      echo "" >> CHANGELOG_NEW.md

      # Insert new entry at the top of existing changelog
      head -n 4 CHANGELOG.md > CHANGELOG_TEMP.md
      cat CHANGELOG_NEW.md >> CHANGELOG_TEMP.md
      tail -n +5 CHANGELOG.md >> CHANGELOG_TEMP.md
      mv CHANGELOG_TEMP.md CHANGELOG.md

      echo "✅ CHANGELOG.md updated"

    # Commit changelog update
    - |
      echo "Committing CHANGELOG.md..."
      git add CHANGELOG.md
      git commit -m "update changelog for v${COLLECTION_VERSION}"

      # Push using GITLAB_RELEASE_TOKEN (already verified above)
      git push https://oauth2:${GITLAB_RELEASE_TOKEN}@oldgitlab.wolskinet.com/ansible/collections/infrastructure.git HEAD:main
      echo "✅ Changelog committed and pushed"

  artifacts:
    paths:
      - RELEASE_NOTES.md
      - CHANGELOG.md
      - "*.tar.gz"
    expire_in: 1 week
  only:
    - main
  when: manual
  environment:
    name: production
    url: $CI_PROJECT_URL/-/releases
